{
  "hash": "32b19bb4bb7b47d86d817c34dddbd1ee",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Market Segmentation with Regression Trees in Python: A Step-by-Step Guide\"\nauthor: \"Yeji Sohn\"\ndate: \"2025-01-18\"\ncategories: [code, analysis]\nimage: \"image.png\"\nbibliography: references.bib\n---\n\n\n\n\nIn the world of data science, one of the most powerful tools for understanding customer behavior and improving marketing strategies is market segmentation. By dividing a market into subgroups with shared characteristics, companies can optimize pricing, enhance customer satisfaction, and allocate resources effectively. In this post, we explore how to use regression trees in Python for market segmentation, providing a step-by-step guide for practical application.\n\n### What is Market Segmentation?\n\n![](image.png)\n\nMarket/Customer segmentation a important tool for identifying \"who\" your target audience is, serving as a key component of your business model. \nIt divides a market into distinct customer groups with similar needs, interests, and priorities, allowing businesses to tailor marketing efforts and products. This process enhances resource allocation and customer satisfaction. \nFor example, a retailer might segment by geography, income, or behavior. \n\nFor this exercise, we'll use user behavior and characteristics (avgerage hours, days visisted, income, etc..) to predict demand elasticities with a regression tree model.\n\nCustomer segmentation in a business model offers several advantages:\n\n#### 1. Effective Marketing Strategy \nSegmentation deepens understanding of customers, allowing businesses to prioritize marketing channels and target specific customer groups with tailored messages and creatives.\n   \n#### 2. Predicting Customer Behavior\nBy classifying customers based on behavior, segmentation helps predict future actions, enabling more proactive strategies.\n\n#### 3. Personalized Customer Experience\nSegmentation allows businesses to offer services tailored to individual customer needs based on their data and create targeted programs, content, and incentives to reward customers and maintain their satisfaction and engagement.\n\n#### 4. Improved Conversion Metrics\nSegmentation boosts conversion rates by enabling personalized strategies. It also helps identify abandoned carts and encourages checkout or purchase.\n\n[@Takyar_2024]\n\n### Key Concepts to Understand\n\n#### 1. Regression Trees\nA machine learning tool that predicts continuous outcomes by splitting data based on input features.\n\n#### 2. CP Value\nComplexity Parameter decides how deep the decision tree will be grown into. If any split does not increase the overall R2 of the model by at least cp, the tree does not split said branch any further\n\n### Sample Dataset\n\nThe dataset is from [@econml] developed by, [Alice Project](https://www.microsoft.com/en-us/research/group/alice/). \n\nThere are around 10,000 observations and 9 continuous and categorical variables representing user's behaviors and characteristics. \n\nDescription of varaibales are as following: \n\n| Feature Name     | Details                                                   |\n|:--- |:---|\n| **account_age**  | user's account age                                        |\n| **age**          | user's age                                                |\n| **avg_hours**    | the average hours user was online per week in the past    |\n| **days_visited** | the average number of days user visited the website per week |\n| **friend_count** | number of friends of user's account                       |\n| **has_membership**| whether the user had membership                          |\n| **is_US**        | whether the user accesses the website from the United States |\n| **songs_purchased**| the average songs user purchased per week (non-discount season) |\n| **income**       | user's income                                             |\n| **price**        | the price user was exposed to during the discount season (baseline price * small discount) |\n| **demand**       | songs user purchased during the discount season          |\n\n### Step-by-Step Guide\n\n#### Step 1: Loading and Preparing the Data\n\nFirst, we load the libraries and data, and perform some basic data cleaning.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import tree\n\nog_df = pd.read_csv(\"https://msalicedatapublic.z5.web.core.windows.net/datasets/Pricing/pricing_sample.csv\")\nog_df.columns = og_df.columns.str.replace(' ', '_').str.lower()  # Clean column names\n```\n\n#### Step 2: Choose number of segments\n\nIn this step, we use a regression tree to identify how many segments (or clusters) we want. \nThe tree's complexity is controlled by a hyperparameter (`ccp_alpha`), which we adjust to visualize the tree structure at different levels of complexity.\n\n```python\ndef show_tree(cp_val, data):\n    reg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\n    reg_tree.fit(data.drop(columns='demand'), data['demand'])\n\n    plt.figure(figsize=(20,10))\n    tree.plot_tree(reg_tree, filled=True, feature_names=data.drop(columns='demand').columns)\n    plt.show()\n\npricing_df = og_df.copy()\n\n# exclude variable of intersts for segmentation\nreg_tree_data = pricing_df.drop(columns=['price'])\n```\n\n```python\nshow_tree(5, reg_tree_data)\n```\n![](../../results/img/tree_cp5.png)\n\n```python\nshow_tree(1, reg_tree_data)\n```\n![](../../results/img/tree_cp1.png)\n\nWe want 4 segments, so we will proceed with cp value of 1.\n\n#### Step 3: Building the Regression Tree\n\nIn this step, we build the actual regression tree model, training it on the user characteristics to predict the demand.\n\n```python\ncp_val = 1\nreg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\nreg_tree.fit(reg_tree_data.drop(columns='demand'), reg_tree_data['demand'])\n```\nBy fitting the model, we are able to identify the relationships between the various user characteristics and demand, and the tree automatically creates splits (segments) based on these variables.\n\n#### Step 4: Assigning Users to Leaves\n\nNext, we assign each user to a regression tree leaf:\n\n```python\npricing_df['leaf'] = reg_tree.apply(reg_tree_data.drop(columns='demand'))\n```\nThis step adds a new variable `leaf` to the dataset, which indicates the leaf (or segment) that each user belongs to.\n\n#### Step 5: Interpreting the Results\n\nAt this point, we have successfully segmented the users based on their characteristics. Each user is now assigned to a segment (leaf) that represents a group of users with similar characteristics.\n\nTo calculate price elasticities for each segment, do the following:\n```python\npricing_df['log_price'] = np.log(pricing_df['price'])\npricing_df['log_q'] = np.log(pricing_df['demand'])\ndata = []\n\n# Elasticity function\ndef own_price_reg(leaf_num):\n    df  = pricing_df[pricing_df['leaf'] == leaf_num]\n    model = smf.ols('log_q ~ log_price', data=df).fit()\n    return model.params['log_price']\n\nfor leaf in pricing_df['leaf'].unique():\n    own_price = own_price_reg(leaf)\n    leaf_data = pricing_df[pricing_df['leaf'] == leaf]\n    avg_values = leaf_data.drop(columns=['leaf']).mean().to_dict()\n    \n    # Add the result to the data list\n    avg_values['leaf'] = leaf\n    avg_values['own_price_reg'] = own_price\n    data.append(avg_values)\n\npd.DataFrame(data)\n```\n\nBoth price and demand are transformed by log.\nThis allows the coefficients to represent elasticity (the percentage change in demand for a percentage change in price).\n\n::: {#tbl-results .cell tbl-cap='Average features and elasticity by segmentation' execution_count=1}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=1}\n|   index |   account_age |     age |   avg_hours |   days_visited |   friends_count |   has_membership |    is_us |   songs_purchased |   income |    price |   demand |   log_price |   log_q |   leaf |   own_price_reg |\n|--------:|--------------:|--------:|------------:|---------------:|----------------:|-----------------:|---------:|------------------:|---------:|---------:|---------:|------------:|--------:|-------:|----------------:|\n|       0 |       3.01726 | 38.9238 |     5.07327 |        1.94948 |        10.0314  |         0.49294  | 0.800439 |           5.10132 | 0.697376 | 0.867587 |  7.78766 |  -0.145771  | 2.02731 |      2 |       -2.14204  |\n|       1 |       2.97933 | 39.4955 |     5.05556 |        5.99788 |         9.97509 |         0.514043 | 0.786963 |           4.98314 | 0.702922 | 0.869104 | 12.753   |  -0.144278  | 2.53648 |      3 |       -1.27903  |\n|       2 |       2.99316 | 38.5003 |     4.97012 |        6.00526 |        10.07    |         0.50868  | 0.793793 |           5.14311 | 1.5587   | 0.958127 | 24.6107  |  -0.0454373 | 3.20234 |      6 |       -0.112743 |\n|       3 |       3.01388 | 38.797  |     4.93473 |        2.01388 |        10.0212  |         0.488926 | 0.807273 |           4.9841  | 1.57671  | 0.958446 | 19.592   |  -0.0450707 | 2.9738  |      5 |       -0.1203   |\n:::\n:::\n\n\n**Group 2:**\n\n* **Price Elasticity (-2.14):** Highly elastic. The demand is sensitive to price changes. A small price increase could significantly reduce demand.\n* **Average Income (0.70):** Relatively low compared to other groups, suggesting higher price sensitivity (income effect).\n* **Average Days Visited (1.95):** Low platform engagement, possibly contributing to higher elasticity as these users might not be habitual buyers.\n* **Interpretation:** Price adjustments could significantly impact demand in this group, making them ideal for sale offerings.\n\n**Group 3:**\n\n* **Price Elasticity (-1.28):** Moderately elastic. Users are still responsive to price changes, but less so than Group 0.\n* **Average Income (0.70):** Similar to Group 2. Moderate price sensitivity.\n* **Average Days Visited (5.99):** Higher engagement than Group 0, which could reduce elasticity as these users are more invested in the platform.\n* **Interpretation:** This group may respond to price changes, but their higher engagement suggests potential for retention despite price increases.\n\n**Group 6:**\n\n* **Price Elasticity (-0.11):** Nearly inelastic. The demand is relatively insensitive to price changes.\n* **Income (1.56):** Higher than the other groups, likely contributing to lower price sensitivity.\n* **Average Days Visited (6.01):** Highest engagement. This could reduce elasticity as these users are more invested in the platform. highly.\n* **Interpretation:** This group can tolerate higher prices without significant reductions in demand, making them ideal for premium offerings.\n\n**Group 5:**\n\n* **Price Elasticity (-0.12):** Nearly inelastic. Similar to Group 6.\n* **Income (1.58):** Comparable to Group 6, supporting lower price sensitivity.\n* **Average Days Visited (2.01):** Despite low platform engagement, demand (19.59) remains high, which could mean that users in this group value the product highly.\n* **Interpretation:** Like Group 6, this group is less price-sensitive and may represent another target for premium pricing or tailored offers.\n\n**Recommendation:**\n\n1. High Elasticity Groups (2 and 3):\n\n   - These groups are more price-sensitive due to lower income, engagement, or both.\n   - Price reductions or promotions may drive significant demand increases.\n\n2. Low Elasticity Groups (6 and 5):\n\n   - These groups show low sensitivity to price changes, likely due to higher income and inherent demand.\n   - They are suitable candidates for price increases or premium-tier products.\n\n\n![](elasticity.PNG)\n\nBy understanding these nuances, pricing and marketing strategies can be tailored to maximize revenue while maintaining user satisfaction.\n\n### Real-World Applications\n\nMarket segmentation using regression trees can be applied to a variety of industries. Here are a few examples:\n\n- **Retail**: Optimize promotions and product offerings based on customer demographics.\n\n- **Healthcare**: Segment patients to tailor treatment plans.\n\n- **Finance**: Offer personalized financial products based on income and behavior.\n\n### Conclusion\n\nIn this blog post, we demonstrated how to segment a market using regression trees in Python. By using regression trees for segmentation, you can uncover actionable insights to drive strategy and decision-making. Whether refining pricing strategies or identifying customer needs, these tools offer a robust way to make the most of your data.\n\nIf you're interested in diving deeper into regression trees or market segmentation, try applying these techniques to your own datasets and explore how different groups behave differently in your industry.\n\n\n\n\n---\n# References\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}